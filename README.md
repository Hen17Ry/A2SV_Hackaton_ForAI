My Sauti - AI-Powered Sign Language Translation

Welcome to the My Sauti GitHub repository! SignSpeak is an AI-based platform designed to bridge the communication gap of the deaf community and their integration into society on all fronts by providing accurate and effective sign language translation on various aspects. This repository contains the source code, development history and support documents for the My Sauti platform.

Structure
This repository is structured as follows:

backend/: Contains the backend code for the My Sauti platform, including API endpoints, database models, and business logic implemented in Python using the Flask framework.

frontend/: Includes the frontend code for the My Sauti platform, implemented using JavaScript, Vue.js, and Vuetify. This directory also contains HTML, CSS, and JavaScript files for the user interface.

mobile/: Contains the source code for the mobile application developed using Dart and Flutter. This directory includes the code for the mobile app that provides sign language translation functionalities.

models/: Contains the trained AI models used by My Sauti to perform sign language translation. These models are implemented using Python-based AI/ML libraries like TensorFlow and are essential for accurate and real-time translations.

data/: Includes datasets used for training and evaluating the AI models. This directory holds the sign language datasets and other relevant data files.

docs/: Contains documentation and related materials, including the README file, user guides, and technical documentation.

Purpose
The purpose of this repository is to provide a collaborative space for the development and enhancement of the My Sauti platform. By making this repository publicly accessible, we aim to encourage community involvement, allowing developers, contributors, and users to explore the codebase, report issues, and suggest improvements.

How AI Models Power My Sauti
My Sauti integrates several AI models to provide comprehensive sign language translation services. Key features include:

Avatar-Based Translation: Converts spoken content into sign language using avatars.
Real-Time Translation: Provides real-time translation for video conferencing and other live interactions.
Mobile Application: Allows users to convert sign language into text and text or voice using their mobile devices.

Generative AI Models Used:
GPT-4: For natural language understanding and processing.
Custom Sign Language Models: For translating spoken content into sign language and vice versa.


Diagram :
    Class Diagram: /Diagramme_class.jpg
    User Case Diagram: /Diagramme_class.jpg
    